{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aircraft Rudder Thermal Imaging Water Ingression Detection - Visual-only CNN\n",
    "==========================================================================\n",
    "Automated water ingression detection in aircraft rudder hoisting points using computer vision only.\n",
    "Target: 84.0% CV accuracy and 93.9% validation test water detection with ResNet50 thermal adaptation.\n",
    "Dataset: 82 thermal images from 15 inspections over 2+ years (60% water vs 40% NWI)\n",
    "Method: ResNet50 with thermal-specific augmentation pipeline (no metadata integration)\n",
    "Key Features: Custom thermal blur/noise/reflection augmentation, palette standardization (89% quality)\n",
    "Performance: Robust blind test results proving visual features sufficient for thermal signatures\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfde098",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pointbiserialr, chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Random seeds for reproducibility\n",
    "def set_random_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seeds(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "CSV_PATH = r\"[METADATA CSV HERE]\" # Folder path here\n",
    "WATER_PATH = r\"[WATER INGRESSION FOLDER PATH HERE]\" # Folder path here\n",
    "NWI_PATH = r\"[NILL WATER INGRESSION FOLDER PATH HERE]\" # Folder path here\n",
    "\n",
    "# Read CSV file (for reference only)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"\\nData Shape: {df.shape}\")\n",
    "print(f\"Water detection rate: {df['Has Water'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc58d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image Augmentation Classes\n",
    "class ThermalBlur:\n",
    "    def __init__(self, blur_limit=(1, 3), p=0.5):\n",
    "        self.blur_limit = blur_limit\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if random.random() < self.p:\n",
    "            blur_radius = random.uniform(*self.blur_limit)\n",
    "            return image.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "        return image\n",
    "\n",
    "class ThermalNoise:\n",
    "    def __init__(self, noise_factor=0.1, p=0.3):\n",
    "        self.noise_factor = noise_factor\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if random.random() < self.p:\n",
    "            img_array = np.array(image, dtype=np.float32)\n",
    "            noise = np.random.normal(0, self.noise_factor * 255, img_array.shape)\n",
    "            noisy_img = np.clip(img_array + noise, 0, 255).astype(np.uint8)\n",
    "            return Image.fromarray(noisy_img)\n",
    "        return image\n",
    "\n",
    "class LightReflection:\n",
    "    def __init__(self, intensity_range=(0.8, 1.3), p=0.3):\n",
    "        self.intensity_range = intensity_range\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if random.random() < self.p:\n",
    "            enhancer = ImageEnhance.Brightness(image)\n",
    "            factor = random.uniform(*self.intensity_range)\n",
    "            return enhancer.enhance(factor)\n",
    "        return image\n",
    "\n",
    "# Transform Strategy (Enhanced for thermal images)\n",
    "def get_thermal_transforms(mode='train'):\n",
    "    if mode == 'train':\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            ThermalBlur(blur_limit=(0.5, 2.0), p=0.4),\n",
    "            LightReflection(intensity_range=(0.8, 1.2), p=0.3),\n",
    "            ThermalNoise(noise_factor=0.05, p=0.2),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)), \n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1dbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset and Model Classes\n",
    "class ThermalVisualDataset(Dataset):\n",
    "    def __init__(self, water_path, nwi_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        # Load water images\n",
    "        if os.path.exists(water_path):\n",
    "            for filename in os.listdir(water_path):\n",
    "                if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append({'path': os.path.join(water_path, filename), 'label': 1, 'file_id': os.path.splitext(filename)[0]})\n",
    "        \n",
    "        # Load NWI images\n",
    "        if os.path.exists(nwi_path):\n",
    "            for filename in os.listdir(nwi_path):\n",
    "                if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append({'path': os.path.join(nwi_path, filename), 'label': 0, 'file_id': os.path.splitext(filename)[0]})\n",
    "        \n",
    "        labels = [s['label'] for s in self.samples]\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        image = Image.open(sample['path']).convert('L')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, sample['label']\n",
    "\n",
    "# CNN Model\n",
    "class ThermalVisualCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2, backbone='resnet50'):\n",
    "        super(ThermalVisualCNN, self).__init__()\n",
    "        \n",
    "        # Image branch only\n",
    "        if backbone == 'resnet50':\n",
    "            self.backbone = models.resnet50(weights='IMAGENET1K_V2')\n",
    "            self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            \n",
    "            # Replace final classification layer\n",
    "            num_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Sequential(\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(num_features, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(128, num_classes)\n",
    "            )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        output = self.backbone(image)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4705bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Functions\n",
    "def evaluate_model_comprehensive(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "    auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "def plot_training_history(history, fold_num):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    epochs = range(1, len(history['train_losses']) + 1)\n",
    "    \n",
    "    # Model Loss\n",
    "    ax1.plot(epochs, history['train_losses'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_losses'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Model Loss - Visual Only', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Model Accuracy\n",
    "    ax2.plot(epochs, history['train_accuracies'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(epochs, history['val_accuracies'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Model Accuracy - Visual Only', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_detailed(y_true, y_pred, title=\"Confusion Matrix - Visual Only\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    annotations = []\n",
    "    for i in range(cm.shape[0]):\n",
    "        row = []\n",
    "        for j in range(cm.shape[1]):\n",
    "            row.append(f'{cm[i,j]}\\n({cm_percent[i,j]:.1f}%)')\n",
    "        annotations.append(row)\n",
    "    \n",
    "    sns.heatmap(cm, annot=annotations, fmt='', cmap='Blues', xticklabels=['NWI', 'Water'], yticklabels=['NWI', 'Water'], cbar_kws={'label': 'Count'})\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_confidence_levels(probabilities, labels, predictions):\n",
    "    probabilities = np.array(probabilities)\n",
    "    labels = np.array(labels)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    high_conf_mask = probabilities >= 0.8\n",
    "    medium_conf_mask = (probabilities >= 0.6) & (probabilities < 0.8)\n",
    "    low_conf_mask = probabilities < 0.6\n",
    "    \n",
    "    results = {}\n",
    "    for mask, level in [(high_conf_mask, 'High (≥0.8)'), (medium_conf_mask, 'Medium (0.6-0.8)'), (low_conf_mask, 'Low (<0.6)')]:\n",
    "        if np.sum(mask) > 0:\n",
    "            conf_labels = labels[mask]\n",
    "            conf_preds = predictions[mask]\n",
    "            accuracy = accuracy_score(conf_labels, conf_preds) if len(conf_labels) > 0 else 0\n",
    "            \n",
    "            results[level] = {'count': np.sum(mask), 'accuracy': accuracy, 'percentage': np.sum(mask) / len(probabilities) * 100}\n",
    "        else:\n",
    "            results[level] = {'count': 0, 'accuracy': 0, 'percentage': 0}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_confidence_analysis(confidence_results):\n",
    "    levels = list(confidence_results.keys())\n",
    "    counts = [confidence_results[level]['count'] for level in levels]\n",
    "    accuracies = [confidence_results[level]['accuracy'] for level in levels]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    colors = ['darkred', 'orange', 'lightcoral']\n",
    "    ax1.bar(levels, counts, color=colors, alpha=0.8)\n",
    "    ax1.set_title('Prediction Count by Confidence Level', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.bar(levels, accuracies, color=colors, alpha=0.8)\n",
    "    ax2.set_title('Accuracy by Confidence Level', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, (count, acc) in enumerate(zip(counts, accuracies)):\n",
    "        ax1.text(i, count + 0.1, str(count), ha='center', fontweight='bold')\n",
    "        ax2.text(i, acc + 0.02, f'{acc:.3f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Function\n",
    "def train_model_with_history(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_predictions.extend(predicted.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_acc = accuracy_score(train_labels, train_predictions)\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        val_metrics = evaluate_model_comprehensive(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(val_metrics['loss'])\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_metrics['accuracy'])\n",
    "        \n",
    "        if val_metrics['accuracy'] > best_val_acc:\n",
    "            best_val_acc = val_metrics['accuracy']\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= 8:\n",
    "            break\n",
    "    \n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses, \n",
    "        'val_losses': val_losses, \n",
    "        'train_accuracies': train_accuracies, \n",
    "        'val_accuracies': val_accuracies, \n",
    "        'best_val_accuracy': best_val_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883efe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Fold Cross Validation\n",
    "def run_kfold_validation_visual_only(water_path, nwi_path, k_folds=5):\n",
    "    all_samples = []\n",
    "    \n",
    "    for filename in os.listdir(water_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            all_samples.append({'path': os.path.join(water_path, filename), 'label': 1, 'file_id': os.path.splitext(filename)[0]})\n",
    "    \n",
    "    for filename in os.listdir(nwi_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            all_samples.append({'path': os.path.join(nwi_path, filename), 'label': 0, 'file_id': os.path.splitext(filename)[0]})\n",
    "    \n",
    "    labels = [sample['label'] for sample in all_samples]\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(all_samples, labels)):\n",
    "        print(f\"\\nFOLD {fold+1}/{k_folds}\")\n",
    "        \n",
    "        train_samples = [all_samples[i] for i in train_idx]\n",
    "        val_samples = [all_samples[i] for i in val_idx]\n",
    "        \n",
    "        train_dataset = ThermalVisualDataset(water_path, nwi_path, transform=get_thermal_transforms('train'))\n",
    "        train_dataset.samples = train_samples\n",
    "        \n",
    "        val_dataset = ThermalVisualDataset(water_path, nwi_path, transform=get_thermal_transforms('val'))\n",
    "        val_dataset.samples = val_samples\n",
    "        \n",
    "        train_labels_fold = [sample['label'] for sample in train_samples]\n",
    "        class_counts = np.bincount(train_labels_fold)\n",
    "        class_weights = 1.0 / class_counts\n",
    "        sample_weights = [class_weights[label] for label in train_labels_fold]\n",
    "        \n",
    "        sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "        \n",
    "        model = ThermalVisualCNN(num_classes=2, backbone='resnet50').to(device)\n",
    "        \n",
    "        class_weights_tensor = torch.FloatTensor([1.0, class_counts[0]/class_counts[1]]).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "        \n",
    "        history = train_model_with_history(model, train_loader, val_loader, criterion, optimizer, scheduler, 30, device)\n",
    "        final_metrics = evaluate_model_comprehensive(model, val_loader, criterion, device)\n",
    "        \n",
    "        if fold == 0:\n",
    "            plot_training_history(history, fold+1)\n",
    "            plot_confusion_matrix_detailed(final_metrics['labels'], final_metrics['predictions'], f\"Confusion Matrix - Visual Only Fold {fold+1}\")\n",
    "            \n",
    "            confidence_results = analyze_confidence_levels(final_metrics['probabilities'], final_metrics['labels'], final_metrics['predictions'])\n",
    "            plot_confidence_analysis(confidence_results)\n",
    "            \n",
    "            print(f\"\\nFold 1 Confidence Analysis:\")\n",
    "            for level, results in confidence_results.items():\n",
    "                print(f\"  {level}: {results['count']} predictions ({results['percentage']:.1f}%) - {results['accuracy']:.1%} accuracy\")\n",
    "        \n",
    "        if final_metrics['accuracy'] > best_accuracy:\n",
    "            best_accuracy = final_metrics['accuracy']\n",
    "            best_model = model\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'train_samples': len(train_samples),\n",
    "            'val_samples': len(val_samples),\n",
    "            'best_val_accuracy': history['best_val_accuracy'],\n",
    "            'final_accuracy': final_metrics['accuracy'],\n",
    "            'final_precision': final_metrics['precision'],\n",
    "            'final_recall': final_metrics['recall'],\n",
    "            'final_f1': final_metrics['f1'],\n",
    "            'final_auc': final_metrics['auc']\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} Results:\")\n",
    "        print(f\"  Best Val Accuracy: {history['best_val_accuracy']:.4f}\")\n",
    "        print(f\"  Final Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Final F1: {final_metrics['f1']:.4f}\")\n",
    "        print(f\"  Final AUC: {final_metrics['auc']:.4f}\")\n",
    "    \n",
    "    return fold_results, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run K-Fold Validation\n",
    "fold_results, best_model = run_kfold_validation_visual_only(WATER_PATH, NWI_PATH, k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results Analysis and Visualization\n",
    "print(\"K-FOLD SUMMARY\")\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nCross-Validation Summary:\")\n",
    "print(f\"  Mean Accuracy: {results_df['final_accuracy'].mean():.4f} ± {results_df['final_accuracy'].std():.4f}\")\n",
    "print(f\"  Mean F1 Score: {results_df['final_f1'].mean():.4f} ± {results_df['final_f1'].std():.4f}\")\n",
    "print(f\"  Mean AUC: {results_df['final_auc'].mean():.4f} ± {results_df['final_auc'].std():.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "metrics = ['final_accuracy', 'final_precision', 'final_recall', 'final_f1', 'final_auc', 'best_val_accuracy']\n",
    "titles = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Best Val Accuracy']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[i//3, i%3]\n",
    "    \n",
    "    bp = ax.boxplot(results_df[metric], labels=[title], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightgreen')\n",
    "    bp['boxes'][0].set_alpha(0.7)\n",
    "    \n",
    "    ax.scatter([1]*len(results_df), results_df[metric], alpha=0.8, s=60, color='darkgreen')\n",
    "    \n",
    "    mean_val = results_df[metric].mean()\n",
    "    ax.axhline(y=mean_val, color='red', linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    ax.set_title(f'{title}\\n(mean={mean_val:.3f}, std={results_df[metric].std():.3f})', fontsize=11, fontweight='bold', pad=15)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.suptitle('Visual-Only K-Fold Cross Validation Results', fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Live Image Testing Function\n",
    "def interpret_confidence(confidence_score):\n",
    "    if confidence_score >= 0.8:\n",
    "        return f\"HIGH CONFIDENCE: {confidence_score:.1%} - Automated decision\"\n",
    "    elif confidence_score >= 0.6:\n",
    "        return f\"MEDIUM CONFIDENCE: {confidence_score:.1%} - Confirmation Needed\"\n",
    "    else:\n",
    "        return f\"LOW CONFIDENCE: {confidence_score:.1%} - Further Review Needed\"\n",
    "\n",
    "def test_single_thermal_image_visual_only(image_path, model):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        transform = get_thermal_transforms('val')\n",
    "        img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            confidence = probs[0, 1].item()\n",
    "            predicted_class = 'Water Detected' if confidence > 0.5 else 'No Water (NWI)'\n",
    "            confidence_interp = interpret_confidence(confidence)\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f'Thermal Image \\n{os.path.basename(image_path)}', fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        if confidence >= 0.8:\n",
    "            bg_color = 'lightgreen' if predicted_class == 'No Water (NWI)' else 'lightcoral'\n",
    "        elif confidence >= 0.6:\n",
    "            bg_color = 'lightyellow'\n",
    "        else:\n",
    "            bg_color = 'lightgray'\n",
    "        \n",
    "        plt.gca().set_facecolor(bg_color)\n",
    "        \n",
    "        y_pos = 0.9\n",
    "        plt.text(0.1, y_pos, f\"Prediction: {predicted_class}\", fontsize=14, weight='bold')\n",
    "        y_pos -= 0.2\n",
    "        plt.text(0.1, y_pos, f\"Confidence: {confidence:.3f}\", fontsize=12)\n",
    "        y_pos -= 0.15\n",
    "        plt.text(0.1, y_pos, confidence_interp, fontsize=11, style='italic')\n",
    "        \n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.axis('off')\n",
    "        plt.title('Visual-Only CNN Results', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"File: {os.path.basename(image_path)}\")\n",
    "        print(f\"Prediction: {predicted_class}\")\n",
    "        print(f\"Confidence: {confidence:.6f}\")\n",
    "        print(f\"Interpretation: {confidence_interp}\")\n",
    "        \n",
    "        return confidence, predicted_class\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Testing failed: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed718600",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Live Testing Example (Remove comment > #)\n",
    "\n",
    "# test_single_thermal_image_visual_only(r\"IMAGE PATH HERE\", best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
